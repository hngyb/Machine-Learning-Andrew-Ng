# 12. Unsupervised Learning
# Clustering
## 12.1 Unsupervised Learning: Introduction
- Supervised learning은 training set의 label이 주어지지만, unsupervised learning은 주어진 label이 없이 training 함.   
- Supervised learning   
    ![](https://wikidocs.net/images/page/4668/uns101.PNG)
- Unsupervised learning   
    ![](https://wikidocs.net/images/page/4668/uns102.PNG)   
## 12.2 K-Means Algorithm
- 주어진 training 데이터를 K-Means algorithm을 이용해서 clustering하는 과정.
    - 임의의 위치에 cluster centroids (빨간 점, 파란 점)를 초기화함.   
    ![](https://wikidocs.net/images/page/4691/uns201.PNG)   
    - 각 데이터를 가장 가까운 centroid에 해당하는 cluster에 배정함.
    - 각 cluster의 데이터 평균을 구해 centroids를 이동함.   
    ![](https://wikidocs.net/images/page/4691/uns202.PNG)   
    - 더 이상 변화가 없을 때까지 같은 과정을 반복함.   
    ![](https://wikidocs.net/images/page/4691/uns203.PNG)   
### K-means algorithm   
  ![1](https://user-images.githubusercontent.com/68726615/92301172-47659e00-ef9c-11ea-8d60-f00ef18f256d.png)   
### K-means for non-separated clusters
  [](https://wikidocs.net/images/page/4691/uns301.PNG)   
## 12.3 Optimization Objective
  ![2](https://user-images.githubusercontent.com/68726615/92301170-459bda80-ef9c-11ea-8de2-3faf744d959a.png)   
    ![](https://wikidocs.net/images/page/4692/uns303.PNG)      
- 이 때, J 함수를 cost function, 또는 distortion이라고 함.
    ![](https://wikidocs.net/images/page/4692/uns304.PNG)   
- Cluster assignment step에서 최적의 c^(1), ..., c^(m)을 찾는 것은 각 example x^(i)가 최적의 cluster에 재배정되는 과정.
- Move centroid step에서 μ^(1), ..., μ^(K)를 구하는 것은 각 cluster를 대표하는 최적값 (여기서는 평균값)을 계산하는 것.
## 12.4 Random Initialization
- Cluster 개수 K 는 데이터 개수 m보다 작아야 함 (K < m).
- 주어진 training example 중 K개를 centroid로 임의로 선택하고 μ1, ..., μk를 그 K개 example과 같게 둠.
- K-means 알고리즘은 초기화에 따라 다른 결과가 나타날 수 있음. 나쁜 경우, local optima에 빠지게 됨.
    ![](https://wikidocs.net/images/page/4693/uns305.PNG)   
### Local Optima   
  ![](https://wikidocs.net/images/page/4693/uns306.PNG)   
- 이 문제는 random initialization을 여러번 하는 것으로 해결할 수 있음.   
    ![](https://wikidocs.net/images/page/4693/uns401.PNG)   
- 아 중 cost가 가장 작은 clustering을 선택함.
- Cluster 개수가 적을수록 local optima에 빠질 확률이 큼.
- Cluster 개수가 적다면 여러번 초기화 해서 고르는 과정을 추천함.
## 12.5 Choosing the Number of Clusters
- Cluster 개수는 사실 아직까지 사람이 manually 결정함.
- 어떤 K가 가장 적절한지에 대한 명확한 답이 없음.
### Elbow method
- K 개수에 따라 cost function J를 그려 보았을 때, 특정 K 이후 cost가 거의 변하지 않는 elbow point가 있다면 그 K를 선택하는 방법.   
    ![](https://wikidocs.net/images/page/4694/uns502.PNG)   
- 그러나 이 방법이 항상 통하지 않음.
- 만약 다음과 같이 J 변화가 대체로 부드럽다면, elbow라고 부를만한 지점이 없음.
- 이 경우, elbow method로 K를 정하는데 무리가 있음.   
    ![](https://wikidocs.net/images/page/4694/uns503.PNG)   
### K-means for a Later Purpose
- K-means를 이후 다른 목적을 위해 사용하는 경우라면, 해당 목적을 잘 만족하는지를 기준으로 K를 결정할 수 있음.
- 예를 들어, t-shirt 사이즈를 결정하는 경우, 예상되는 이익이 극대화되는 사이즈 종류 수를 선택하면 됨.   
    ![](https://wikidocs.net/images/page/4694/uns504.PNG)