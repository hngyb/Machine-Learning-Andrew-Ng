# 1. Introduction

## 1.1 Welcome

**머신러닝**

- 인공지능 분야에서 발전하여 파생됨
- 컴퓨터의 새로운 능력 (기초과학과 산업의 여러 분야에서 사용됨)

**머신러닝의 예시**

- Database mining (데이베이스 수집)
    - Large datasets from growth of automation/web.
    - E.g. Web click data, medical records, biology, engineering
- Applications can't program by hand (수동적으로 프로그래밍을 할 수 없을 때 사용하는 자동화 학습 프로그래밍 분야)
    - E.g. Autonomous helicopter, handwriting recognition, most of Natural Language Processing (NLP), Computer Vision
- Self-customizing programs
    - E.g. Amazon, Netflix product recommendations
- Understanding human learning (brain, real AI)

## 1.2 What is Machine Learning?

### 머신러닝의 정의

1. **Arthur Samuel (1959)**
> Field of study that gives computers the ability to learn without being explicitly programmed. (컴퓨터가 명시적 프로그램이 없어도 스스로 학습할 수 있는 능력을 연구하는 학문 분야)
- 다소 오래되고, 추상적인 정의

2. **Tom Mitchell (1998)**

> Well-posed Learning Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.
- Apply to Checker game
    - 경험(E): 같은 게임을 수만 번 반복하는 과정
    - 작업(T): 체커 게임을 수행하는 행위
    - 성능(P): 프로그램이 다음 판에 새로운 상대를 만났을 때, 그 판을 이길 확률
- Apply to Spam Check
    - 경험(E): Watching you label emails as spam or not spam
    - 작업(T): Classifying emails as spam or not spam
    - 성능(P): The number of emails correctly classified as spam/not spam

### 머신러닝 알고리즘의 분류

- Supervised learning (지도학습)
- Unsupervised learning (비지도학습)
- Others: Reinforcement learning (강화학습), recommender systems (추천시스템)

## 1.3 Supervised Learning

- "지도학습"은 우리가 알고리즘에게 데이터 집합을 주는데, 각 데이터에 '정답'이 포함돼있는 것. In supervised learning, we are given a data set and **already know what our correct output should look like**, having the idea that there is a relationship between the input and the output.
- 예를 들어 집에 대한 데이터 집합을 제공했다면, 각 집마다 정확한 가격도 함께 알려준 것 .
- 지도학습 문제는 **"회귀(Regression)"와 "분류(Classification)"** 문제로 나뉘어짐.

### 회귀(Regression)

- Predict results within a continuous output (연속적인 결과값)
- Map input variables to some continuous function
- E.g. 집의 넓이에 해당하는 적절한 집값을 추정하는 문제

![Untitled](https://user-images.githubusercontent.com/68726615/88475940-4b4edb00-cf6f-11ea-8400-7c8217a7efa7.png)   
출처: [https://wikidocs.net/images/page/4209/INT101.PNG](https://wikidocs.net/images/page/4209/INT101.PNG)

### 분류(Classification)

- Predict results in a discrete output (이산적인 결과값)
- Map input variables into discrete categories
- E.g. 종양이 악성인지 양성인지 진단하는 문제
    - 진단 결과가 악성/양성으로 discrete category이므로 classification   
![Untitled 1](https://user-images.githubusercontent.com/68726615/88475936-49851780-cf6f-11ea-9494-759973e48039.png)   
출처: [https://wikidocs.net/images/page/4209/INT102.PNG](https://wikidocs.net/images/page/4209/INT102.PNG)

![Untitled 2](https://user-images.githubusercontent.com/68726615/88475937-4a1dae00-cf6f-11ea-893d-9ca2927e8764.png)   
출처: [https://wikidocs.net/images/page/4209/INT201.PNG](https://wikidocs.net/images/page/4209/INT201.PNG)

- 서포트 벡터 머신(Support Vector Machine)이라는 알고리즘을 통해 무한한 개수의 특성을 다룰 수 있음.

## 1.4 Unsupervised Learning

- "비지도 학습"에서는 데이터가 어떤 레이블도 갖고 있지 않거나, 모두 같은 레이블을 갖고 있거나, 아예 레이블이 없음. Unsupervised learning allows us to approach problems with little or no idea what our results should look like.
- 주어진 데이터에서 어떤 구조를 찾을 수 있을까에 대한 문제.
- 데이터의 변수들 간의 관계에 기반한 clustering으로 어떤 구조를 도출해냄. We can derive this structure by clustering the data based on relationships among the variables in the data.
- 즉, 비지도 학습에는 예측 결과값에 대해 피드백이 없음.

### Clustering

![Untitled 3](https://user-images.githubusercontent.com/68726615/88475938-4a1dae00-cf6f-11ea-9452-60de549d4214.png)   
출처: [https://wikidocs.net/images/page/4209/INT202.PNG](https://wikidocs.net/images/page/4209/INT202.PNG)

- E.g.
    - 구글 뉴스: 수만 개의 기사들을 연관성이 있는 것끼리 묶어줌.
    - DNA 미세배열: Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on.
    - Organize computing clusters
    - Market segmentation
    - Social network analysis
    - Astronomical data analysis

### Non-clustering

- E.g. The "Cocktail Party Algorithm", allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds at a cocktail party).

![Untitled 4](https://user-images.githubusercontent.com/68726615/88475939-4ab64480-cf6f-11ea-83b4-3afea98f295c.png)   
출처: [https://wikidocs.net/images/page/4209/INT203.PNG](https://wikidocs.net/images/page/4209/INT203.PNG)
