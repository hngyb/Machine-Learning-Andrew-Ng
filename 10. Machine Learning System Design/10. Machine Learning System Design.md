# 10. Machine Learning System Design
# Building a Spam Classifier
## 10.1 Prioritizing What to Work On
### System Design Example
- spam classifier를 build할 때, spam/non-spam을 구별할 수 있는 단어 100개를 추려서 feature x는 그러한 단어가 email에 포함되었는지 여부를 나타내는 vector로 표현할 수 있음.   
    ![](https://user-images.githubusercontent.com/68726615/93431705-7adeeb80-f8ff-11ea-80c5-dbc71bf44828.png)     
- 실제로는 수동으로 100개 단어를 뽑기보다는 training set에서 가장 자주 나타나는 단어 n개 (10,000 ~ 50,000)를 선택함.
- 어떻게 하면 classifier의 정확도를 향상 시킬 수 있을까?
    - 데이터를 많이 모음. ("honeypot" project, but doesn't always work)
    - 정교한 features 개발함. (for example: using email header data in spam emails)
    - Email 본문에 기반한 알고리즘을 개선함.
    - 의도적으로 철자를 틀리게 쓴 단어를 검출하는 알고리즘을 개선함. (for example: m0rgage, med1cine, w4tches...)
## 10.2 Error Analysis
### Recommended approach
1. 빠르게 구현할 수 있는 간단한 알고리즘으로 시작. 구현한 후 cross-validation data로 테스트.
2. Learning curv를 그려서 데이터를 늘리거나, feature를 늘리거나, 혹은 다른 어떤 방법이 도움이 될지 결정.
3. Error analysis: 에러를 일으키는 데이터(in cross-validation set)를 수동으로 분석. 어떤 종류의 데이터가 일정한 경향의 에러를 발생시키는지 관찰
- 예를 들어, 500Ro cross-validation data 중 100개 Email이 잘못 분류되었다고 하면, 이 100가지 에러를 manually 분석하여 다음과 같은 기준에 의해 분류함.
    (i) What type of email it is
    (ii) What cues (features) you think would helped the algorithm classify them correctly
- (i)의 경우,
    - 약팔이: 12개, 짝퉁: 4개, 피싱: 53개, 기타: 31개 였다면, '피싱'으로 분류된 메일에 대한 성능을 높이는 방법을 찾는 것이 가장 효과적임.
- (ii)의 경우,
    - 의도적인 철자법 오류: 5건, unusual email routing: 16건, unusual punctuation: 32건 이었다면 'unusual punctuation'을 검출하는 방법을 찾는 것이 효과적임.
### The Importance of Numerical Evaluation
- discount/discounts/discounted/discounting 등의 단어들은 "stemming" software를 사용하면 같은 단어로 취급할 수 있음.
- 문제는 universe와 university를 같은 단어로 취급하는 등의 에러를 발생시킬 수 있음.
- Error analysis만으로는 stemming을 하는 것이 성능 향상에 도움이 될지 알기 어려움.
- 한가지 방법은 일단 시도해보고 효과가 있는지 판단하는 것임.
- 이 때, numerical evaluation (e.g., cross validation error)가 필요함.
- 즉, stemming을 이용할 때와 이용하지 않을 때의 에러율을 비교하여 걸정을 내리면 됨.
# Handling Skewed Data
## 10.3 Error Metrics for Skewed Classes
### Cancer classification example
- 환자의 0.5%만이 실제로 암이라면, 항상 y = 0 으로 결정하는 알고리즘만으로도 0.5% 에러율을 달성할 수 있음.
- 이렇게 class별 데이터 수 차이가 많이 나는 데이터를 __skewed data__ 라고 함.
- 이러한 경우, 에러율만으로는 성능을 정확하게 평가할 수 없음.
### Precision / Recall
- 에러율 대신 성능을 평가할 수 있는 metric에는 precision과 recall 이 있음.
- 일반적으로, y = 1 in presence of __rare class__ that we want to detect.   
    ![](https://wikidocs.net/images/page/4662/des301.PNG "")   
- __Precision__ :  y = 1 로 예측한 환자들 중, 실제로 암환자는 얼마인가?   
    ![](https://wikidocs.net/images/page/4662/des302.PNG "")   
- __Recall__ : 실제로 암인 환자들 중, 얼마만큼을 정확히 찾아내었는가?   
    ![](https://wikidocs.net/images/page/4662/des303.PNG "")   
## 10.4 Trading Off Precision and Recall
### Trading off precision and recall   
  ![](https://wikidocs.net/images/page/4662/des401.PNG "")   
- Suppose we want to predict y = 1 (cancer) only if very confident.
    - Higher precision, lower recall
- Suppose we want to avoid missing too many cases of cancer
    - Higher recall, lower precision   
    ![](https://wikidocs.net/images/page/4662/des403.PNG "")   
- 최적의 threshold를 어떻게 결정할까?
### F1 Score (F Score)   
  ![](https://wikidocs.net/images/page/4662/des404.PNG "")   
- Precision과 Reall의 평균을 내는 것은 좋은 선택이 아님. y = 1로 항상 결정하는 알고리즘도 평균값은 높을 수 있기 때문. (Algorithm 3)   
    ![](https://wikidocs.net/images/page/4662/des405.PNG "")   
- 대신 F-Score가 일반적으로 쓰임.   
    ![1](https://user-images.githubusercontent.com/68726615/90596010-072abf80-e229-11ea-9295-3a2ae5aab472.png "")   
- 만약 P = 0 or R = 0 이면 F-score는 0이 되고, 완벽한 알고리즘의 경우 P = 1. R = 1 이 되어 F-score가 1이 됨.   
    ![](https://wikidocs.net/images/page/4662/des406.PNG "")   
# Using Large Data Sets
## 10.5 Data For Machine Learning   
  ![](https://wikidocs.net/images/page/4663/des501.PNG "")   
- 대부분의 알고리즘들이 training data가 늘어날 수록 성능이 향상됨.
- "약한 알고리즘"도 데이터만 많으면 "강한 알고리즘" 만큼의 성능을 내는 것이 가능함.
### Large Data Rationale 1
- Assume feature x∈ℝ^(n+1) has sufficient information to predict y accurately
- 예: For breakfast I ate __ eggs.
- 반례: Housing price를 평수만으로 예측하기 (아무리 데이터 개수가 많아도 입지, 방 개수 등의 조건 없이 평수만으로 집값을 정확하게 예측하기는 어려움)
- 이 조건을 만족하는지 확인하는 방법은 사람(전문가)이 주어진 x로 y를 믿을만하게 예측할 수 있는 가를 따져보는 것.
### Large Data Rationale 2
- Use a learning algorithm with many parameters. (예: Logistic/Linear regression with many features; Neural networks with many hidden units)
- 많은 parameter와 매우 많은 training set을 동시에 사용하면 overfit할 가능성도 함께 줄어들게 되어 low bias와 low variance를 동시에 충족할 수 있게 됨.   
    ![](https://wikidocs.net/images/page/4663/des601.PNG "")