# 9. Advice for Applying Machine Learning
# Evaluating a Learning Algorithm
## 9.1 Deciding What to Try Next
### Debugging a Learning Algorithm
- hypothesis를 test할 때, 예측 에러가 굉장히 크다면, 어떤 방법을 취할 수 있을까?
    - Training example을 늘림.
    - Feature 개수를 줄임.
    - Polynomial feature를 추가함.
    - λ를 늘림.
    - λ를 줄임.
- 그러나 이러한 방법들을 하나하나 시도해보는 것은 오랜 시간이 걸림.
- __Machine learning diagnostic__ 를 통해 learning algorithm에 대한 insight를 얻고, 어떻게 performance를 향상시킬지 guidance를 얻을 수 있음.
- Diagnostic은 실행하는데 시간이 걸리지만, 충분히 가치가 있는 일임.
## 9.2 Evaluating a Hypothesis
- hypothesis를 evaluate하기 위해, 주어진 training examples를 __training set__ 과 __test set__ 으로 나눌 수 있음.
- 일반적으로 70%의 데이터를 training set으로, 나머지를 test set으로 나눔.
    ![](https://wikidocs.net/images/page/4655/adv202.PNG "")
- The new procedure using these two sets is then:
    1. Learn Θ and minimize Jtrain(Θ) using the training set.
    2. Compute the test set error Jtest(Θ).
### The test set error
- For linear regression:   
    ![1](https://user-images.githubusercontent.com/68726615/90367237-88584a00-e0a3-11ea-8e62-278f60e36771.png "")   
- For classification ~ Misclassification error (aka 0/1 misclassification error):   
    ![2](https://user-images.githubusercontent.com/68726615/90367235-87bfb380-e0a3-11ea-8872-62d43876a76d.png "")   
    - The average test error for the test set is:   
        ![3](https://user-images.githubusercontent.com/68726615/90367233-87271d00-e0a3-11ea-8ed2-e28fef200d8f.png "")   
## 9.3 Model selection and Train/Validation/Test Sets
- Training set에 대해서 정한 parameters θ0, θ1, ..., θ4를 이용해서 계산한 에러 (training error J(θ))는 실제 에러보다 작을 가능성이 높음.
### Model selection   
  ![](https://wikidocs.net/images/page/4655/adv301.PNG "")   
- 이렇게 계산된 일련의 Jtest() 중 d = 5 일 때의 test error가 가장 작아서 이를 선택했다면, 이 때 Jtest(θ^(5))는 generalization error의 optimistic estimate일 가능성이 높음. test set에 대해서 fit 되었기 때문.
- 그러므로 주어진 데이터를 단순히 training/test로 나누기보다, d를 fit하기 위한 set 역시 만들어야 함.   
    ![](https://wikidocs.net/images/page/4655/adv401.PNG "")
- cross validation set을 만듦.   
    ![4](https://user-images.githubusercontent.com/68726615/90367223-84c4c300-e0a3-11ea-8c0b-a34f94dc32a8.png "")   
- d를 결정하는 문제는 이제 cross validation set을 이용함.
    ![](https://wikidocs.net/images/page/4655/adv403.PNG "")
# Bias vs. Variance   
## 9.4 Diagnosing Bias vs. Variance
  ![](https://wikidocs.net/images/page/4655/adv501.PNG "")   
- Polynomial order d에 대하여 Jcv(θ)와 Jtrain(θ)를 그려보면 training error는 d가 커질수록 줄어들지만, corss validation error는 intermediate 값에서 최적값을 가짐.   
    ![](https://user-images.githubusercontent.com/68726615/93431216-c8a72400-f8fe-11ea-8b1c-a4f66ed0c876.png)   
### Diagnosing bias vs. variance
- bias 문제인지, variance 문제인지 판단하는 방법은?
    ![](https://wikidocs.net/images/page/4655/adv601.PNG "")
- High bias (underfit) 은 Jtrain(θ) 이 크다. Jcv(θ) ≈ Jtrain(θ)인 형태임.
- High variance (overfit)는  Jtrain(θ)은 작은데 Jcv(θ)은 큰 것, Jcv(θ) ≫ Jtrain(θ)인 것으로 확인할 수 있음.
## 9.5 Regularization and Bias/Variance   
  ![](https://wikidocs.net/images/page/4655/adv702.PNG "")   
- λ가 너무 크면 underfit가 되고, λ너무 작으면 regularization항이 거의 영향을 미치지 못해 overfit하게 됨.
### Choosing the regularization parameter λ
- Cross-validation set을 이용해서 λ를 선택함.   
  ![](https://wikidocs.net/images/page/4655/adv802.PNG "")   
  ![](https://wikidocs.net/images/page/4655/adv803.PNG "")   
## 9.6 Learning Curves
- Training example 개수에 따라 error 그래프를 그려보는 것으로 overfit/underfit을 진단할 수 있음. 이러한 그래프를 __learning curve__ 라고 함.
    ![](https://wikidocs.net/images/page/4658/adv901.PNG "")
### High bias   
  ![](https://user-images.githubusercontent.com/68726615/93431437-17ed5480-f8ff-11ea-9861-5406c26fb2c0.png)     
    ![](https://wikidocs.net/images/page/4658/adv902.PNG "")
- High bias의 특징은, Training error와 cv error가 모두 크다는 것임.
- Learning algorithm이 high bias 문제를 겪고 있다면, 단순히 training data를 늘리는 것은 큰 효과가 없음.
### High Variance   
  ![](https://user-images.githubusercontent.com/68726615/93431434-16239100-f8ff-11ea-9ef1-c34aab3f7709.png)   
    ![](https://wikidocs.net/images/page/4658/adv903.PNG "")
- High variance가 발생할 경우에는, training error와 cv error의 차이가 큼.
- 이때에는, training data를 늘리는 것이 도움이 될 수 있음.
## 9.7 Deciding What to Do Next Revisited
### Debugging a learning algorithm
- large error를 발견했을 때, What should you try next?
    - Training example을 늘림. -> fix high variance
    - Feature 개수를 줄임. -> fix high variance
    - Feature 개수를 추가함. -> fix high bias
    - Polynomial feature를 추가함. -> fix high bias
    - λ를 늘림. -> fix high variance
    - λ를 줄임. -> fix high bias
### Neural networks and overfitting   
  ![](https://wikidocs.net/images/page/4659/adv1001.PNG "")