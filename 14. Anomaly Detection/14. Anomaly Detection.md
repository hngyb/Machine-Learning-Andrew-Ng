# 14. Anomaly Detection
# Density Estimation
## 14.1 Problem Motivation
### Anomaly detection example
- 비행기 엔진을 제작하는 공장에서 불량품을 걸러내는 방법 개발.
- 발열과 진동 세기를 feature로 사용.   
    ![](https://wikidocs.net/images/page/4670/ano101.PNG)   
- 정상 작동하는 다수의 엔진들(training data)로부터 측정한 feature 값들 (빨간 점)과 test하고싶은 엔진에서 측정한 feature값(파란 점)을 비교하여 불량 여부 파악 가능함.   
    ![](https://wikidocs.net/images/page/4670/ano102.PNG)   
### Density estimation
  ![](https://wikidocs.net/images/page/4696/ano103.PNG)   
- 수집한 데이터로부터 feature의 확률분포 p(x)를 모델링하여 새로운 데이터 xtest가 해당 확률분포를 따를 likelihood를 계산하여 이 likelihood가 특정한 threshold ϵ보다 크면 정상, 그렇지 않으면 비정상으로 판단함.
### Examples
- Fraud detection
- Manufacturing
- Monitoring computers in a data center
## 14.2 Gaussian Distribution
  ![](https://wikidocs.net/images/page/4696/ano202.PNG)   
- 주어진 dataset의 x가 정규분포를 따른다고 가정함.   
    ![](https://wikidocs.net/images/page/4696/ano204.PNG)   
- 이 때의 parameter μ와 σ는 다음과 같이 추정함.   
    ![](https://wikidocs.net/images/page/4696/ano205.PNG)   
## 14.3 Algorithm
### Density Estimation
  ![](https://wikidocs.net/images/page/4696/ano302.PNG)   
### Anomaly Detection Algorithm
1. Anomalous example을 판별할 수 있을 것으로 생각되는 features xi, 1≤i≤n 를 고름. 이 때 n은 feature dimension, 혹은 사용할 feature의 개수임.
2. Parameters μ와 σ를 구함.   
    ![1](https://user-images.githubusercontent.com/68726615/92617476-4a44f380-f2fa-11ea-8f03-022c370c874b.png)   
3. 새 example x에 대하여 p(x)를 구함.   
    ![2](https://user-images.githubusercontent.com/68726615/92617468-474a0300-f2fa-11ea-9fcc-68c6bee5b992.png)   
# Building an Anomaly Detection System
## 14.4 Developing and Evaluating an Anomaly Detection System
### The importance of real-number evaluation
- Learning algorithm을 개발할 때 알고리즘을 양적으로 평가할 수 있는 방법이 있으면 feature를 선택하는 등의 결정을 내리기가 수월해짐.
- Anomalous/non-anomalous label 데이터가 있다고 가정함. 정상이면 y = 0, 비정상이면 y = 1 이라고 표시.   
    ![](https://wikidocs.net/images/page/4697/ano401.PNG)   
### Aircraft Engines Example
- 정상 엔진 10,000개, 불량 엔진 20개가 있다고 가정.   
    ![](https://wikidocs.net/images/page/4697/ano402.PNG)   
    ![](https://wikidocs.net/images/page/4697/ano403.PNG)   
### Algorithm Evaluation
- Fit model p(x) on training set x
- On a cross-validation/test example x, predict   
    ![](https://wikidocs.net/images/page/4697/ano501.PNG)   
- Possible evaluation metrics: Note this is skewed data!
    - True positive, false positive, false negative, true negative
    - Precision/recall
    - F-score
- Cross-validation set을 이용하여 parameter ϵ를 정할 수 있음.
## 14.5 Anomaly Detection vs. Supervised Learning   
  ![](https://wikidocs.net/images/page/4697/ano502.PNG)   
- Anomaly detection은 positive example을 학습할 충분한 데이터가 없을 때, Supervised learning은 충분한 positive example이 있을 때 각각 사용함.
## 14.6 Choosing What Features to Use
### Non-Gaussian Features
- feature가 Gausian distribution을 따르지 않을 때, logarithm이나 polynomial 등을 이용하여 feature transformation을 할 수 있음.   
    ![](https://wikidocs.net/images/page/4698/ano601.PNG)
### Error analysis for anomaly detection
- Anomaly detection을 할 때, 이상적인 것은
    - p(x) large for normal examples x.
    - p(x) small for anomalous examples x.
- 하지만 정상과 비정상 사례의 p(x)가 모두 비슷한 범위에 존재, 즉 둘 다 큰 경우가 흔히 발생함.
- 이 때에는 anomalous 하지만 p(x)가 큰 경우를 따로 뽑아 자세히 분석하여 새 feature를 고안해내는 방법을 시도함.   
    ![](https://wikidocs.net/images/page/4698/ano602.PNG)   
### Monitoring computers in a data center
- Choose features that might take on unusually large or small values in the event of an anomaly.
    - x1 = memory use of computer
    - x2 = number of disk accessess/sec
    - x3 = CPU load
    - x4 = network traffic
    - x5 = CPU load/network traffic